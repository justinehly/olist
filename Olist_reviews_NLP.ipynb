{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XtHbAdYWGXAG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "jBrYcmKVGmcT",
    "outputId": "9649f155-fe4f-4393-a447-1753ff8a96bf"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WIrHiFPoGmgG"
   },
   "outputs": [],
   "source": [
    "#import io\n",
    "#olist_reviews = pd.read_csv(io.BytesIO(uploaded['olist_order_reviews_dataset.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\olani\\\\OneDrive\\\\Documents\\\\Data Science\\\\SMU-Data Science\\\\Machine Learning 1\\\\Olist_Dataset\\\\Olist_Datasets'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change working directory\n",
    "os.chdir(r\"C:\\Users\\olani\\OneDrive\\Documents\\Data Science\\SMU-Data Science\\Machine Learning 1\\Olist_Dataset\\Olist_Datasets\")\n",
    "#\"C:\\Users\\olani\\OneDrive\\Documents\\Data Science\\SMU-Data Science\\Machine Learning 1\\Olist_Dataset\"\n",
    "\n",
    "# get current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up some colors and text attributes to markdown\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "olist_reviews = pd.read_csv('olist_order_reviews_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "nSxqc4bxGmjy",
    "outputId": "806e0fd9-5a8c-440a-c985-e14337d08b7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17 00:00:00</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
       "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
       "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "\n",
       "   review_score review_comment_title  \\\n",
       "0             4                  NaN   \n",
       "1             5                  NaN   \n",
       "2             5                  NaN   \n",
       "3             5                  NaN   \n",
       "4             5                  NaN   \n",
       "\n",
       "                              review_comment_message review_creation_date  \\\n",
       "0                                                NaN  2018-01-18 00:00:00   \n",
       "1                                                NaN  2018-03-10 00:00:00   \n",
       "2                                                NaN  2018-02-17 00:00:00   \n",
       "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
       "4  Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
       "\n",
       "  review_answer_timestamp  \n",
       "0     2018-01-18 21:46:59  \n",
       "1     2018-03-11 03:05:13  \n",
       "2     2018-02-18 14:36:24  \n",
       "3     2017-04-21 22:02:06  \n",
       "4     2018-03-02 10:26:53  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-zELQLCGmnR",
    "outputId": "291a91d1-ec16-4caf-8a5c-4b5491b8380b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(olist_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tN5D8jDGmsO",
    "outputId": "1a7104e6-8b32-4fd5-970b-ff19632086cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   review_id                100000 non-null  object\n",
      " 1   order_id                 100000 non-null  object\n",
      " 2   review_score             100000 non-null  int64 \n",
      " 3   review_comment_title     11715 non-null   object\n",
      " 4   review_comment_message   41753 non-null   object\n",
      " 5   review_creation_date     100000 non-null  object\n",
      " 6   review_answer_timestamp  100000 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "olist_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVpNapZWGmuD",
    "outputId": "0f01f259-6100-4506-fdde-072fe3638c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (41753, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41753 entries, 0 to 41752\n",
      "Data columns (total 2 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   review_score            41753 non-null  int64 \n",
      " 1   review_comment_message  41753 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 652.5+ KB\n"
     ]
    }
   ],
   "source": [
    "olist_rev = olist_reviews.loc[:, ['review_score', 'review_comment_message']]\n",
    "olist_rev = olist_rev.dropna(subset=['review_comment_message'])\n",
    "olist_rev = olist_rev.reset_index(drop=True)\n",
    "print(f'Dataset shape: {olist_rev.shape}')\n",
    "olist_rev.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9NoRcS8jK1e"
   },
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "piQD34fXGmyq"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOln-baFjgt4"
   },
   "source": [
    "#### Breakline and Carriage Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "V_el7QOKGm0b"
   },
   "outputs": [],
   "source": [
    "def re_breakline(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_list: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    return [re.sub('[\\n\\r]', ' ', r) for r in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4YXqENzGm44",
    "outputId": "ba0efc57-b3ad-4fc8-d949-7beb1954d854"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recebi bem antes do prazo estipulado.',\n",
       " 'Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa',\n",
       " 'aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho',\n",
       " 'Mas um pouco ,travando...pelo valor ta Boa.\\r\\n',\n",
       " 'Vendedor confiável, produto ok e entrega antes do prazo.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list of comment reviews\n",
    "reviews = list(olist_rev['review_comment_message'].values)\n",
    "\n",
    "# Applying RegEx\n",
    "reviews_breakline = re_breakline(reviews)\n",
    "olist_rev['re_breakline'] = reviews_breakline\n",
    "\n",
    "# Verifying results\n",
    "#print(reviews, reviews_breakline, idx_list=[48])\n",
    "reviews_breakline[:5]\n",
    "reviews[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4iPGF3jdGm-F"
   },
   "outputs": [],
   "source": [
    "def re_hiperlinks(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_list: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    pattern = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return [re.sub(pattern, ' link ', r) for r in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fp83AXNOGnB0"
   },
   "outputs": [],
   "source": [
    "# Applying RegEx\n",
    "reviews_hiperlinks = re_hiperlinks(reviews_breakline)\n",
    "olist_rev['re_hiperlinks'] = reviews_hiperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XGjsmnXLmIZ0"
   },
   "outputs": [],
   "source": [
    "#Dates\n",
    "def re_dates(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_list: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    pattern = '([0-2][0-9]|(3)[0-1])(\\/|\\.)(((0)[0-9])|((1)[0-2]))(\\/|\\.)\\d{2,4}'\n",
    "    return [re.sub(pattern, ' data ', r) for r in text_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UhhG7_QnmIgz"
   },
   "outputs": [],
   "source": [
    "# Applying RegEx\n",
    "reviews_dates = re_dates(reviews_hiperlinks)\n",
    "olist_rev['re_dates'] = reviews_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HPY04T5umIkd"
   },
   "outputs": [],
   "source": [
    "#Money\n",
    "def re_money(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_list: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    pattern = '[R]{0,1}\\$[ ]{0,}\\d+(,|\\.)\\d+'\n",
    "    return [re.sub(pattern, ' dinheiro ', r) for r in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SAQKeFADmInk"
   },
   "outputs": [],
   "source": [
    "# Applying RegEx\n",
    "reviews_money = re_money(reviews_dates)\n",
    "olist_rev['re_money'] = reviews_money\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "eP4crDSWmIrK"
   },
   "outputs": [],
   "source": [
    "def re_numbers(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_series: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    return [re.sub('[0-9]+', ' numero ', r) for r in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "30wfoIknmIuP"
   },
   "outputs": [],
   "source": [
    "# Applying RegEx\n",
    "reviews_numbers = re_numbers(reviews_money)\n",
    "olist_rev['re_numbers'] = reviews_numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-FQVYoGsO0e"
   },
   "source": [
    "Removing negation stop words makes it difficult to see the semantics/sentiment of the comment.\n",
    "- So we can replace common negation words with another word that indicates negation and that is not in the stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AfeDZXSAmIyF"
   },
   "outputs": [],
   "source": [
    "#Negation\n",
    "def re_negation(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_series: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    return [re.sub('([nN][ãÃaA][oO]|[ñÑ]| [nN] )', ' negação ', r) for r in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "svUK3jJ1mI0Q"
   },
   "outputs": [],
   "source": [
    "# Applying RegEx\n",
    "reviews_negation = re_negation(reviews_numbers)\n",
    "olist_rev['re_negation'] = reviews_negation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0A4U6KpWmI3s"
   },
   "outputs": [],
   "source": [
    "#Special Characters\n",
    "def re_special_chars(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_series: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    return [re.sub('\\W', ' ', r) for r in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kKm2veYrmJVp"
   },
   "outputs": [],
   "source": [
    "# Applying RegEx\n",
    "reviews_special_chars = re_special_chars(reviews_negation)\n",
    "olist_rev['re_special_chars'] = reviews_special_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "KMDh-NTkmJZG"
   },
   "outputs": [],
   "source": [
    "#Additional whitespaces\n",
    "def re_whitespaces(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_series: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    white_spaces = [re.sub('\\s+', ' ', r) for r in text_list]\n",
    "    white_spaces_end = [re.sub('[ \\t]+$', '', r) for r in white_spaces]\n",
    "    return white_spaces_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "SJQI3LAPmJct"
   },
   "outputs": [],
   "source": [
    "# Applying RegEx\n",
    "reviews_whitespaces = re_whitespaces(reviews_special_chars)\n",
    "olist_rev['re_whitespaces'] = reviews_whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "4sDeQD27uRU9"
   },
   "outputs": [],
   "source": [
    "#.drop(columns=['stemming', 'stopwords_removed'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mNPAOadJxokY",
    "outputId": "0bd69270-e488-486c-9531-860c7b0c0ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41753 entries, 0 to 41752\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   review_score            41753 non-null  int64 \n",
      " 1   review_comment_message  41753 non-null  object\n",
      " 2   re_breakline            41753 non-null  object\n",
      " 3   re_hiperlinks           41753 non-null  object\n",
      " 4   re_dates                41753 non-null  object\n",
      " 5   re_money                41753 non-null  object\n",
      " 6   re_numbers              41753 non-null  object\n",
      " 7   re_negation             41753 non-null  object\n",
      " 8   re_special_chars        41753 non-null  object\n",
      " 9   re_whitespaces          41753 non-null  object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "olist_rev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WRepRr3s_fd",
    "outputId": "d5790909-adbb-4bb4-b567-8b05d4a6710b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\olani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zzf-UQRsvHJ",
    "outputId": "ede42760-b980-4027-9811-39942cfa2235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total portuguese stopwords in the nltk.corpous module: 204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing stop words after replacing negation stop words.\n",
    "pt_stopwords = stopwords.words('portuguese')\n",
    "print(f'Total portuguese stopwords in the nltk.corpous module: {len(pt_stopwords)}')\n",
    "pt_stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "q-IJu_3gtE85"
   },
   "outputs": [],
   "source": [
    "# Defining a function to remove the stopwords and to lower the comments\n",
    "def stopwords_removal(text, cached_stopwords=stopwords.words('portuguese')):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text: list object where the stopwords will be removed [type: list]\n",
    "    cached_stopwords: stopwords to be applied on the process [type: list, default: stopwords.words('portuguese')]\n",
    "    \"\"\"\n",
    "    \n",
    "    return [c.lower() for c in text.split() if c.lower() not in cached_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "d1iyf4xVsvOw"
   },
   "outputs": [],
   "source": [
    "# Removing stopwords and looking at some examples\n",
    "reviews_stopwords = [' '.join(stopwords_removal(review)) for review in reviews_whitespaces]\n",
    "olist_rev['stopwords_removed'] = reviews_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZUm8ULsGnE4",
    "outputId": "74490f37-209d-4c76-e024-38b73e7a1986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\olani\\anaconda3\\envs\\Machine' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/stanfordnlp/stanza.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E3DsSMFVoHrE",
    "outputId": "212a2a90-6ef0-4121-b72f-79228bb64461"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stanza'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-9bd8c6f8611e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Alternative lemmatizer for Portuguese\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#https://lars76.github.io/2018/05/08/portuguese-lemmatizers.html#7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstanza\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mstanza\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'stanza'"
     ]
    }
   ],
   "source": [
    "#Alternative lemmatizer for Portuguese\n",
    "#https://lars76.github.io/2018/05/08/portuguese-lemmatizers.html#7\n",
    "import stanza\n",
    "stanza.download('pt')\n",
    "nlp = stanza.Pipeline('pt')\n",
    "\n",
    "text = \"\"\n",
    "pos = \"\"\n",
    "lemma = \"\"\n",
    "for sent in nlp(\"Não, minha miúda no sentido que és como uma irmã para mim.\").sentences:\n",
    "    for word in sent.words:\n",
    "        text += word.text + \"\\t\"\n",
    "        pos += word.upos + \"\\t\"\n",
    "        lemma += word.lemma + \"\\t\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t72hpvhUoHuM",
    "outputId": "3004eed5-09c1-4cb1-f361-2c9468e7ff21"
   },
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline('pt')\n",
    "\n",
    "text = \"\"\n",
    "pos = \"\"\n",
    "lemma = \"\"\n",
    "for sent in nlp(\"Não, minha miúda no sentido que és como uma irmã para mim.\").sentences:\n",
    "    for word in sent.words:\n",
    "        text += word.text + \"\\t\"\n",
    "        pos += word.upos + \"\\t\"\n",
    "        lemma += word.lemma + \"\\t\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "XF2oAR3zoHyw",
    "outputId": "7e827b65-939b-491c-e853-f72b044ab24b"
   },
   "outputs": [],
   "source": [
    "lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "bmF8az5LoH0J"
   },
   "outputs": [],
   "source": [
    "#Using NLTK Stemmer\n",
    "# Defining a function to remove the stopwords and to lower the comments\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANxkHj_LrSrV",
    "outputId": "d06a288a-ed91-4f41-b510-e13ad6b95da7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\olani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "N03xSVnFrLrS"
   },
   "outputs": [],
   "source": [
    "def stemming_process(text, stemmer=RSLPStemmer()):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text: list object where the stopwords will be removed [type: list]\n",
    "    stemmer: type of stemmer to be applied [type: class, default: RSLPStemmer()]\n",
    "    \"\"\"\n",
    "    \n",
    "    return [stemmer.stem(c) for c in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "OphQlc0boH38"
   },
   "outputs": [],
   "source": [
    "# Applying stemming and looking at some examples\n",
    "reviews_stemmer = [' '.join(stemming_process(review)) for review in reviews_stopwords]\n",
    "olist_rev['stemming'] = reviews_stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "G8FBLYgOoH5k",
    "outputId": "2e706cdf-7a44-4f8c-e371-16035ce21c0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>re_hiperlinks</th>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re_dates</th>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re_money</th>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re_numbers</th>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re_negation</th>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re_special_chars</th>\n",
       "      <td>Recebi bem antes do prazo estipulado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re_whitespaces</th>\n",
       "      <td>Recebi bem antes do prazo estipulado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords_removed</th>\n",
       "      <td>recebi bem antes prazo estipulado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stemming</th>\n",
       "      <td>receb bem ant praz estipul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "re_hiperlinks      Recebi bem antes do prazo estipulado.\n",
       "re_dates           Recebi bem antes do prazo estipulado.\n",
       "re_money           Recebi bem antes do prazo estipulado.\n",
       "re_numbers         Recebi bem antes do prazo estipulado.\n",
       "re_negation        Recebi bem antes do prazo estipulado.\n",
       "re_special_chars   Recebi bem antes do prazo estipulado \n",
       "re_whitespaces      Recebi bem antes do prazo estipulado\n",
       "stopwords_removed      recebi bem antes prazo estipulado\n",
       "stemming                      receb bem ant praz estipul"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_rev.iloc[:1, 3:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPVGHNQcoH9A",
    "outputId": "c17ea15a-8117-49e0-c3ce-cffe09b9ba30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41753 entries, 0 to 41752\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   review_score            41753 non-null  int64 \n",
      " 1   review_comment_message  41753 non-null  object\n",
      " 2   re_breakline            41753 non-null  object\n",
      " 3   re_hiperlinks           41753 non-null  object\n",
      " 4   re_dates                41753 non-null  object\n",
      " 5   re_money                41753 non-null  object\n",
      " 6   re_numbers              41753 non-null  object\n",
      " 7   re_negation             41753 non-null  object\n",
      " 8   re_special_chars        41753 non-null  object\n",
      " 9   re_whitespaces          41753 non-null  object\n",
      " 10  stopwords_removed       41753 non-null  object\n",
      " 11  stemming                41753 non-null  object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "olist_rev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "sbW4c6jhGnIx"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtBW3sxYGnLm",
    "outputId": "bb30e53b-30c8-4108-cc00-0e57fd7f72cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41753x8146 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 296360 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(olist_rev['stemming'])\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5jz-O-QGnP7",
    "outputId": "555ca585-ec3c-42ee-b659-386d36084862"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "mO1tzs1RGnSd"
   },
   "outputs": [],
   "source": [
    "vocab = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "K-2DTpWYGnWq",
    "outputId": "f3c4080c-7b3b-4794-ba08-49f609eafe1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa</th>\n",
       "      <th>aaguard</th>\n",
       "      <th>aaind</th>\n",
       "      <th>aanch</th>\n",
       "      <th>aaprelh</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>...</th>\n",
       "      <th>ônibu</th>\n",
       "      <th>ônu</th>\n",
       "      <th>ötim</th>\n",
       "      <th>últ</th>\n",
       "      <th>úmid</th>\n",
       "      <th>únic</th>\n",
       "      <th>úte</th>\n",
       "      <th>útel</th>\n",
       "      <th>útil</th>\n",
       "      <th>ünic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41748</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41749</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41750</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41751</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41752</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41753 rows × 8146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       __  aa  aaa  aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa  \\\n",
       "0       0   0    0                                                      0   \n",
       "1       0   0    0                                                      0   \n",
       "2       0   0    0                                                      0   \n",
       "3       0   0    0                                                      0   \n",
       "4       0   0    0                                                      0   \n",
       "...    ..  ..  ...                                                    ...   \n",
       "41748   0   0    0                                                      0   \n",
       "41749   0   0    0                                                      0   \n",
       "41750   0   0    0                                                      0   \n",
       "41751   0   0    0                                                      0   \n",
       "41752   0   0    0                                                      0   \n",
       "\n",
       "       aaguard  aaind  aanch  aaprelh  ab  aba  ...  ônibu  ônu  ötim  últ  \\\n",
       "0            0      0      0        0   0    0  ...      0    0     0    0   \n",
       "1            0      0      0        0   0    0  ...      0    0     0    0   \n",
       "2            0      0      0        0   0    0  ...      0    0     0    0   \n",
       "3            0      0      0        0   0    0  ...      0    0     0    0   \n",
       "4            0      0      0        0   0    0  ...      0    0     0    0   \n",
       "...        ...    ...    ...      ...  ..  ...  ...    ...  ...   ...  ...   \n",
       "41748        0      0      0        0   0    0  ...      0    0     0    0   \n",
       "41749        0      0      0        0   0    0  ...      0    0     0    0   \n",
       "41750        0      0      0        0   0    0  ...      0    0     0    0   \n",
       "41751        0      0      0        0   0    0  ...      0    0     0    0   \n",
       "41752        0      0      0        0   0    0  ...      0    0     0    0   \n",
       "\n",
       "       úmid  únic  úte  útel  útil  ünic  \n",
       "0         0     0    0     0     0     0  \n",
       "1         0     0    0     0     0     0  \n",
       "2         0     0    0     0     0     0  \n",
       "3         0     0    0     0     0     0  \n",
       "4         0     0    0     0     0     0  \n",
       "...     ...   ...  ...   ...   ...   ...  \n",
       "41748     0     0    0     0     0     0  \n",
       "41749     0     0    0     0     0     0  \n",
       "41750     0     0    0     0     0     0  \n",
       "41751     0     0    0     0     0     0  \n",
       "41752     0     0    0     0     0     0  \n",
       "\n",
       "[41753 rows x 8146 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show document feature vectors\n",
    "pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Py3Dl4lGnZ-",
    "outputId": "be94b079-63e7-4925-9f98-a964ee901595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 875 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# you can set the n-gram range to 1,2 to get unigrams as well as bigrams\n",
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "bv_matrix = bv.fit_transform(olist_rev['stemming'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcVpC5816pOn",
    "outputId": "141397da-1f24-41bd-eed5-d06a87cddf35"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 28.3 GiB for an array with shape (41753, 90926) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 28.3 GiB for an array with shape (41753, 90926) and data type int64"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#System crashed\n",
    "#bv_matrix = bv_matrix.toarray()\n",
    "#vocab = bv.get_feature_names()\n",
    "#pd.DataFrame(bv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "gIu4VQga6pSo"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Eb3ZSeaA6pWi"
   },
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(min_df=0., max_df=1., norm='l2', use_idf=True, smooth_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "TI5eLBN26paS",
    "outputId": "222d46bf-5493-4da9-ee36-48cc0fa785e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa</th>\n",
       "      <th>aaguard</th>\n",
       "      <th>aaind</th>\n",
       "      <th>aanch</th>\n",
       "      <th>aaprelh</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>...</th>\n",
       "      <th>ônibu</th>\n",
       "      <th>ônu</th>\n",
       "      <th>ötim</th>\n",
       "      <th>últ</th>\n",
       "      <th>úmid</th>\n",
       "      <th>únic</th>\n",
       "      <th>úte</th>\n",
       "      <th>útel</th>\n",
       "      <th>útil</th>\n",
       "      <th>ünic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41748</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41749</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41750</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41751</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41752</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41753 rows × 8146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        __   aa  aaa  aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa  \\\n",
       "0      0.0  0.0  0.0                                                    0.0   \n",
       "1      0.0  0.0  0.0                                                    0.0   \n",
       "2      0.0  0.0  0.0                                                    0.0   \n",
       "3      0.0  0.0  0.0                                                    0.0   \n",
       "4      0.0  0.0  0.0                                                    0.0   \n",
       "...    ...  ...  ...                                                    ...   \n",
       "41748  0.0  0.0  0.0                                                    0.0   \n",
       "41749  0.0  0.0  0.0                                                    0.0   \n",
       "41750  0.0  0.0  0.0                                                    0.0   \n",
       "41751  0.0  0.0  0.0                                                    0.0   \n",
       "41752  0.0  0.0  0.0                                                    0.0   \n",
       "\n",
       "       aaguard  aaind  aanch  aaprelh   ab  aba  ...  ônibu  ônu  ötim  últ  \\\n",
       "0          0.0    0.0    0.0      0.0  0.0  0.0  ...    0.0  0.0   0.0  0.0   \n",
       "1          0.0    0.0    0.0      0.0  0.0  0.0  ...    0.0  0.0   0.0  0.0   \n",
       "2          0.0    0.0    0.0      0.0  0.0  0.0  ...    0.0  0.0   0.0  0.0   \n",
       "3          0.0    0.0    0.0      0.0  0.0  0.0  ...    0.0  0.0   0.0  0.0   \n",
       "4          0.0    0.0    0.0      0.0  0.0  0.0  ...    0.0  0.0   0.0  0.0   \n",
       "...        ...    ...    ...      ...  ...  ...  ...    ...  ...   ...  ...   \n",
       "41748      0.0    0.0    0.0      0.0  0.0  0.0  ...    0.0  0.0   0.0  0.0   \n",
       "41749      0.0    0.0    0.0      0.0  0.0  0.0  ...    0.0  0.0   0.0  0.0   \n",
       "41750      0.0    0.0    0.0      0.0  0.0  0.0  ...    0.0  0.0   0.0  0.0   \n",
       "41751      0.0    0.0    0.0      0.0  0.0  0.0  ...    0.0  0.0   0.0  0.0   \n",
       "41752      0.0    0.0    0.0      0.0  0.0  0.0  ...    0.0  0.0   0.0  0.0   \n",
       "\n",
       "       úmid  únic  úte  útel  útil  ünic  \n",
       "0       0.0   0.0  0.0   0.0   0.0   0.0  \n",
       "1       0.0   0.0  0.0   0.0   0.0   0.0  \n",
       "2       0.0   0.0  0.0   0.0   0.0   0.0  \n",
       "3       0.0   0.0  0.0   0.0   0.0   0.0  \n",
       "4       0.0   0.0  0.0   0.0   0.0   0.0  \n",
       "...     ...   ...  ...   ...   ...   ...  \n",
       "41748   0.0   0.0  0.0   0.0   0.0   0.0  \n",
       "41749   0.0   0.0  0.0   0.0   0.0   0.0  \n",
       "41750   0.0   0.0  0.0   0.0   0.0   0.0  \n",
       "41751   0.0   0.0  0.0   0.0   0.0   0.0  \n",
       "41752   0.0   0.0  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[41753 rows x 8146 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_matrix = tv.fit_transform(olist_rev['stemming'])\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "vocab = tv.get_feature_names()\n",
    "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-bc2872d33fc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "W9wGRHk16pcx"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.53 GiB for an array with shape (41753, 8146) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-5fe2b17b178b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msimilarity_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtv_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msimilarity_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#similarity_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1180\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1182\u001b[1;33m     \u001b[0mX_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1183\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_normalized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1904\u001b[0m     X = check_array(X, accept_sparse=sparse_format, copy=copy,\n\u001b[1;32m-> 1905\u001b[1;33m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m   1906\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1907\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.53 GiB for an array with shape (41753, 8146) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(tv_matrix)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "#similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOWk1c0O6pg2"
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "Z = linkage(similarity_matrix, 'ward')\n",
    "pd.DataFrame(Z, columns=['Document\\Cluster 1', 'Document\\Cluster 2', 'Distance', 'Cluster Size'], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "X7c61FQo6pi_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>re_breakline</th>\n",
       "      <th>re_hiperlinks</th>\n",
       "      <th>re_dates</th>\n",
       "      <th>re_money</th>\n",
       "      <th>re_numbers</th>\n",
       "      <th>re_negation</th>\n",
       "      <th>re_special_chars</th>\n",
       "      <th>re_whitespaces</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>Recebi bem antes do prazo estipulado</td>\n",
       "      <td>Recebi bem antes do prazo estipulado</td>\n",
       "      <td>recebi bem antes prazo estipulado</td>\n",
       "      <td>receb bem ant praz estipul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa</td>\n",
       "      <td>parabéns lojas lannister adorei comprar internet seguro prático parabéns todos feliz páscoa</td>\n",
       "      <td>parabém loj lannist ador compr internet segur prát parabém tod feliz pásco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho</td>\n",
       "      <td>aparelho eficiente  no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome   atualizar com a marca correta uma vez que é o mesmo aparelho</td>\n",
       "      <td>aparelho eficiente no site a marca do aparelho esta impresso como numero desinfector e ao chegar esta com outro nome atualizar com a marca correta uma vez que é o mesmo aparelho</td>\n",
       "      <td>aparelho eficiente site marca aparelho impresso numero desinfector chegar outro nome atualizar marca correta vez aparelho</td>\n",
       "      <td>aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.</td>\n",
       "      <td>Mas um pouco  travando   pelo valor ta Boa</td>\n",
       "      <td>Mas um pouco travando pelo valor ta Boa</td>\n",
       "      <td>pouco travando valor ta boa</td>\n",
       "      <td>pouc trav val ta boa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes do prazo.</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes do prazo.</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes do prazo.</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes do prazo.</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes do prazo.</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes do prazo.</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes do prazo.</td>\n",
       "      <td>Vendedor confiável  produto ok e entrega antes do prazo</td>\n",
       "      <td>Vendedor confiável produto ok e entrega antes do prazo</td>\n",
       "      <td>vendedor confiável produto ok entrega antes prazo</td>\n",
       "      <td>vend confi produt ok entreg ant praz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_score  \\\n",
       "0             5   \n",
       "1             5   \n",
       "2             4   \n",
       "3             4   \n",
       "4             5   \n",
       "\n",
       "                                                                                                                                                           review_comment_message  \\\n",
       "0                                                                                                                                           Recebi bem antes do prazo estipulado.   \n",
       "1                                                                            Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa   \n",
       "2  aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho   \n",
       "3                                                                                                                                 Mas um pouco ,travando...pelo valor ta Boa.\\r\\n   \n",
       "4                                                                                                                        Vendedor confiável, produto ok e entrega antes do prazo.   \n",
       "\n",
       "                                                                                                                                                                     re_breakline  \\\n",
       "0                                                                                                                                           Recebi bem antes do prazo estipulado.   \n",
       "1                                                                            Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa   \n",
       "2  aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho   \n",
       "3                                                                                                                                   Mas um pouco ,travando...pelo valor ta Boa.     \n",
       "4                                                                                                                        Vendedor confiável, produto ok e entrega antes do prazo.   \n",
       "\n",
       "                                                                                                                                                                    re_hiperlinks  \\\n",
       "0                                                                                                                                           Recebi bem antes do prazo estipulado.   \n",
       "1                                                                            Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa   \n",
       "2  aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho   \n",
       "3                                                                                                                                   Mas um pouco ,travando...pelo valor ta Boa.     \n",
       "4                                                                                                                        Vendedor confiável, produto ok e entrega antes do prazo.   \n",
       "\n",
       "                                                                                                                                                                         re_dates  \\\n",
       "0                                                                                                                                           Recebi bem antes do prazo estipulado.   \n",
       "1                                                                            Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa   \n",
       "2  aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho   \n",
       "3                                                                                                                                   Mas um pouco ,travando...pelo valor ta Boa.     \n",
       "4                                                                                                                        Vendedor confiável, produto ok e entrega antes do prazo.   \n",
       "\n",
       "                                                                                                                                                                         re_money  \\\n",
       "0                                                                                                                                           Recebi bem antes do prazo estipulado.   \n",
       "1                                                                            Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa   \n",
       "2  aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho   \n",
       "3                                                                                                                                   Mas um pouco ,travando...pelo valor ta Boa.     \n",
       "4                                                                                                                        Vendedor confiável, produto ok e entrega antes do prazo.   \n",
       "\n",
       "                                                                                                                                                                              re_numbers  \\\n",
       "0                                                                                                                                                  Recebi bem antes do prazo estipulado.   \n",
       "1                                                                                   Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa   \n",
       "2  aparelho eficiente. no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho   \n",
       "3                                                                                                                                          Mas um pouco ,travando...pelo valor ta Boa.     \n",
       "4                                                                                                                               Vendedor confiável, produto ok e entrega antes do prazo.   \n",
       "\n",
       "                                                                                                                                                                             re_negation  \\\n",
       "0                                                                                                                                                  Recebi bem antes do prazo estipulado.   \n",
       "1                                                                                   Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa   \n",
       "2  aparelho eficiente. no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho   \n",
       "3                                                                                                                                          Mas um pouco ,travando...pelo valor ta Boa.     \n",
       "4                                                                                                                               Vendedor confiável, produto ok e entrega antes do prazo.   \n",
       "\n",
       "                                                                                                                                                                        re_special_chars  \\\n",
       "0                                                                                                                                                  Recebi bem antes do prazo estipulado    \n",
       "1                                                                                   Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa   \n",
       "2  aparelho eficiente  no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome   atualizar com a marca correta uma vez que é o mesmo aparelho   \n",
       "3                                                                                                                                          Mas um pouco  travando   pelo valor ta Boa      \n",
       "4                                                                                                                               Vendedor confiável  produto ok e entrega antes do prazo    \n",
       "\n",
       "                                                                                                                                                                      re_whitespaces  \\\n",
       "0                                                                                                                                               Recebi bem antes do prazo estipulado   \n",
       "1                                                                               Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa   \n",
       "2  aparelho eficiente no site a marca do aparelho esta impresso como numero desinfector e ao chegar esta com outro nome atualizar com a marca correta uma vez que é o mesmo aparelho   \n",
       "3                                                                                                                                            Mas um pouco travando pelo valor ta Boa   \n",
       "4                                                                                                                             Vendedor confiável produto ok e entrega antes do prazo   \n",
       "\n",
       "                                                                                                           stopwords_removed  \\\n",
       "0                                                                                          recebi bem antes prazo estipulado   \n",
       "1                                parabéns lojas lannister adorei comprar internet seguro prático parabéns todos feliz páscoa   \n",
       "2  aparelho eficiente site marca aparelho impresso numero desinfector chegar outro nome atualizar marca correta vez aparelho   \n",
       "3                                                                                                pouco travando valor ta boa   \n",
       "4                                                                          vendedor confiável produto ok entrega antes prazo   \n",
       "\n",
       "                                                                                            stemming  \n",
       "0                                                                         receb bem ant praz estipul  \n",
       "1                         parabém loj lannist ador compr internet segur prát parabém tod feliz pásco  \n",
       "2  aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh  \n",
       "3                                                                               pouc trav val ta boa  \n",
       "4                                                               vend confi produt ok entreg ant praz  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_rev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "4rEGygd96pm9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemming</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>receb bem ant praz estipul</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parabém loj lannist ador compr internet segur prát parabém tod feliz pásco</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pouc trav val ta boa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vend confi produt ok entreg ant praz</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gost sab sempr receb compr agor decpcion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>péss</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loj not numer</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>obrig atença amim dispens</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>compr realiz facil entreg efetu ant praz dad produt começ ser us pres problem</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>relógi bonit barat</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>neg gost compr gat lebr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sempr compr internet entreg ocorr ant praz combin acredit ser praz máx stark praz máx esgot aind neg receb produt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>receb exat esper demal encomend outr vend atras cheg praz</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recom</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>boa</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tô complet apaixon loj sup respons confi</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nad cheg ped</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bom cheir</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>otim vend cheg ate ant praz ador produt</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             stemming  \\\n",
       "0                                                                                          receb bem ant praz estipul   \n",
       "1                                          parabém loj lannist ador compr internet segur prát parabém tod feliz pásco   \n",
       "2                   aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh   \n",
       "3                                                                                                pouc trav val ta boa   \n",
       "4                                                                                vend confi produt ok entreg ant praz   \n",
       "5                                                                            gost sab sempr receb compr agor decpcion   \n",
       "6                                                                                                                péss   \n",
       "7                                                                                                       loj not numer   \n",
       "8                                                                                           obrig atença amim dispens   \n",
       "9                                       compr realiz facil entreg efetu ant praz dad produt começ ser us pres problem   \n",
       "10                                                                                                 relógi bonit barat   \n",
       "11                                                                                            neg gost compr gat lebr   \n",
       "12  sempr compr internet entreg ocorr ant praz combin acredit ser praz máx stark praz máx esgot aind neg receb produt   \n",
       "13                                                          receb exat esper demal encomend outr vend atras cheg praz   \n",
       "14                                                                                                              recom   \n",
       "15                                                                                                                boa   \n",
       "16                                                                           tô complet apaixon loj sup respons confi   \n",
       "17                                                                                                       nad cheg ped   \n",
       "18                                                                                                          bom cheir   \n",
       "19                                                                            otim vend cheg ate ant praz ador produt   \n",
       "\n",
       "    review_score  \n",
       "0              5  \n",
       "1              5  \n",
       "2              4  \n",
       "3              4  \n",
       "4              5  \n",
       "5              2  \n",
       "6              1  \n",
       "7              5  \n",
       "8              5  \n",
       "9              5  \n",
       "10             5  \n",
       "11             1  \n",
       "12             1  \n",
       "13             4  \n",
       "14             5  \n",
       "15             5  \n",
       "16             5  \n",
       "17             1  \n",
       "18             5  \n",
       "19             5  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_rev_clean2 = olist_rev[['stemming', 'review_score']]\n",
    "olist_rev_clean2.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "VKTc0CJK6psp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41753 entries, 0 to 41752\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   stemming            41753 non-null  object  \n",
      " 1   review_score        41753 non-null  int64   \n",
      " 2   review_score_class  41753 non-null  category\n",
      "dtypes: category(1), int64(1), object(1)\n",
      "memory usage: 693.4+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olani\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\olani\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# let's break up the Discrepancy variable\n",
    "#But needs outliers to be removed\n",
    "olist_rev_clean2['review_score_class'] = pd.cut(olist_rev_clean2['review_score'],\n",
    "                                                 [0, 2, 3, 5],\n",
    "                                                 3,\n",
    "                                                 labels=['bad','fair','good']) # this creates a new variable\n",
    "olist_rev_clean2['review_score_class'] = olist_rev_clean2.copy()['review_score_class'].astype(\"category\")\n",
    "olist_rev_clean2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemming</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_score_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>receb bem ant praz estipul</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parabém loj lannist ador compr internet segur prát parabém tod feliz pásco</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pouc trav val ta boa</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vend confi produt ok entreg ant praz</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gost sab sempr receb compr agor decpcion</td>\n",
       "      <td>2</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>péss</td>\n",
       "      <td>1</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loj not numer</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>obrig atença amim dispens</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>compr realiz facil entreg efetu ant praz dad produt começ ser us pres problem</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>relógi bonit barat</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>neg gost compr gat lebr</td>\n",
       "      <td>1</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sempr compr internet entreg ocorr ant praz combin acredit ser praz máx stark praz máx esgot aind neg receb produt</td>\n",
       "      <td>1</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>receb exat esper demal encomend outr vend atras cheg praz</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recom</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>boa</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tô complet apaixon loj sup respons confi</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nad cheg ped</td>\n",
       "      <td>1</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bom cheir</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>otim vend cheg ate ant praz ador produt</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             stemming  \\\n",
       "0                                                                                          receb bem ant praz estipul   \n",
       "1                                          parabém loj lannist ador compr internet segur prát parabém tod feliz pásco   \n",
       "2                   aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh   \n",
       "3                                                                                                pouc trav val ta boa   \n",
       "4                                                                                vend confi produt ok entreg ant praz   \n",
       "5                                                                            gost sab sempr receb compr agor decpcion   \n",
       "6                                                                                                                péss   \n",
       "7                                                                                                       loj not numer   \n",
       "8                                                                                           obrig atença amim dispens   \n",
       "9                                       compr realiz facil entreg efetu ant praz dad produt começ ser us pres problem   \n",
       "10                                                                                                 relógi bonit barat   \n",
       "11                                                                                            neg gost compr gat lebr   \n",
       "12  sempr compr internet entreg ocorr ant praz combin acredit ser praz máx stark praz máx esgot aind neg receb produt   \n",
       "13                                                          receb exat esper demal encomend outr vend atras cheg praz   \n",
       "14                                                                                                              recom   \n",
       "15                                                                                                                boa   \n",
       "16                                                                           tô complet apaixon loj sup respons confi   \n",
       "17                                                                                                       nad cheg ped   \n",
       "18                                                                                                          bom cheir   \n",
       "19                                                                            otim vend cheg ate ant praz ador produt   \n",
       "\n",
       "    review_score review_score_class  \n",
       "0              5               good  \n",
       "1              5               good  \n",
       "2              4               good  \n",
       "3              4               good  \n",
       "4              5               good  \n",
       "5              2                bad  \n",
       "6              1                bad  \n",
       "7              5               good  \n",
       "8              5               good  \n",
       "9              5               good  \n",
       "10             5               good  \n",
       "11             1                bad  \n",
       "12             1                bad  \n",
       "13             4               good  \n",
       "14             5               good  \n",
       "15             5               good  \n",
       "16             5               good  \n",
       "17             1                bad  \n",
       "18             5               good  \n",
       "19             5               good  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_rev_clean2.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "No5-5I-t6puk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemming</th>\n",
       "      <th>review_score_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>receb bem ant praz estipul</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parabém loj lannist ador compr internet segur prát parabém tod feliz pásco</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pouc trav val ta boa</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vend confi produt ok entreg ant praz</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            stemming  \\\n",
       "0                                                                         receb bem ant praz estipul   \n",
       "1                         parabém loj lannist ador compr internet segur prát parabém tod feliz pásco   \n",
       "2  aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh   \n",
       "3                                                                               pouc trav val ta boa   \n",
       "4                                                               vend confi produt ok entreg ant praz   \n",
       "\n",
       "  review_score_class  \n",
       "0               good  \n",
       "1               good  \n",
       "2               good  \n",
       "3               good  \n",
       "4               good  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_rev_clean3 = olist_rev_clean2.copy().drop(['review_score'], axis=1) # axis=1 means column\n",
    "olist_rev_clean3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "nGMGVupz6pzV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemming</th>\n",
       "      <th>review_score_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>receb bem ant praz estipul</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parabém loj lannist ador compr internet segur prát parabém tod feliz pásco</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pouc trav val ta boa</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vend confi produt ok entreg ant praz</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41748</th>\n",
       "      <td>entreg dentr praz produt cheg cond perfeit satisfeit</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41749</th>\n",
       "      <td>produt neg envi nf neg exist vend nf cert fic aguard envi nf pod ser mail</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41750</th>\n",
       "      <td>excel mochil entreg sup rápid sup recom loj</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41751</th>\n",
       "      <td>solicit compr cap retrovi celt prism meriv pret lad esquerd cheg mim cap lad direit outr model carr decepcion fic aguard</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41752</th>\n",
       "      <td>produt cheg ja devolv poi defeit neg segur carg</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41753 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                       stemming  \\\n",
       "0                                                                                                    receb bem ant praz estipul   \n",
       "1                                                    parabém loj lannist ador compr internet segur prát parabém tod feliz pásco   \n",
       "2                             aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh   \n",
       "3                                                                                                          pouc trav val ta boa   \n",
       "4                                                                                          vend confi produt ok entreg ant praz   \n",
       "...                                                                                                                         ...   \n",
       "41748                                                                      entreg dentr praz produt cheg cond perfeit satisfeit   \n",
       "41749                                                 produt neg envi nf neg exist vend nf cert fic aguard envi nf pod ser mail   \n",
       "41750                                                                               excel mochil entreg sup rápid sup recom loj   \n",
       "41751  solicit compr cap retrovi celt prism meriv pret lad esquerd cheg mim cap lad direit outr model carr decepcion fic aguard   \n",
       "41752                                                                           produt cheg ja devolv poi defeit neg segur carg   \n",
       "\n",
       "      review_score_class  \n",
       "0                   good  \n",
       "1                   good  \n",
       "2                   good  \n",
       "3                   good  \n",
       "4                   good  \n",
       "...                  ...  \n",
       "41748               good  \n",
       "41749               fair  \n",
       "41750               good  \n",
       "41751                bad  \n",
       "41752                bad  \n",
       "\n",
       "[41753 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_rev_clean3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qmi7aYCG6ppP"
   },
   "outputs": [],
   "source": [
    "comments_stemmed = []\n",
    "for stem in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "mtgik2B46p1l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recebi bem antes prazo estipulado',\n",
       " 'parabéns lojas lannister adorei comprar internet seguro prático parabéns todos feliz páscoa',\n",
       " 'aparelho eficiente site marca aparelho impresso numero desinfector chegar outro nome atualizar marca correta vez aparelho',\n",
       " 'pouco travando valor ta boa',\n",
       " 'vendedor confiável produto ok entrega antes prazo',\n",
       " 'gostaria saber sempre recebi compra agora decpcionou',\n",
       " 'péssimo',\n",
       " 'loja nota numero',\n",
       " 'obrigado atençao amim dispensada',\n",
       " 'compra realizada facilmente entrega efetuada antes prazo dado produto começou ser usado presente problemas',\n",
       " 'relógio bonito barato',\n",
       " 'negação gostei comprei gato lebre',\n",
       " 'sempre compro internet entrega ocorre antes prazo combinado acredito ser prazo máximo stark prazo máximo esgotou ainda negação recebi produto',\n",
       " 'recebi exatamente esperava demais encomendas outros vendedores atrasaram chegou prazo',\n",
       " 'recomendo']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_stopwords[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "xMQ1MNM66p5c"
   },
   "outputs": [],
   "source": [
    "import googletrans\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "OVdAR6qH6p8y"
   },
   "outputs": [],
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B18SANtb6qBk"
   },
   "outputs": [],
   "source": [
    "for words in reviews_stopwords:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "YQI8RVFT6qFb"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-60339df4d19e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrev_translations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreviews_stopwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mrev_translations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#reviews_eng = reviews_stopwords.apply(translator.translate)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\googletrans\\client.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0morigin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;31m# this code will be updated when the format is changed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\googletrans\\client.py\u001b[0m in \u001b[0;36m_translate\u001b[1;34m(self, text, dest, src, override)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRANSLATE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pick_service_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpx\\_client.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url, params, headers, cookies, auth, allow_redirects, timeout)\u001b[0m\n\u001b[0;32m    761\u001b[0m             \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_redirects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m             \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m         )\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpx\\_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, data, files, json, params, headers, cookies, auth, allow_redirects, timeout)\u001b[0m\n\u001b[0;32m    599\u001b[0m         )\n\u001b[0;32m    600\u001b[0m         return self.send(\n\u001b[1;32m--> 601\u001b[1;33m             \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_redirects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m         )\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpx\\_client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, auth, allow_redirects, timeout)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         response = self.send_handling_redirects(\n\u001b[1;32m--> 621\u001b[1;33m             \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_redirects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m         )\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpx\\_client.py\u001b[0m in \u001b[0;36msend_handling_redirects\u001b[1;34m(self, request, auth, timeout, allow_redirects, history)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m             response = self.send_handling_auth(\n\u001b[1;32m--> 648\u001b[1;33m                 \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m             )\n\u001b[0;32m    650\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpx\\_client.py\u001b[0m in \u001b[0;36msend_handling_auth\u001b[1;34m(self, request, history, auth, timeout)\u001b[0m\n\u001b[0;32m    682\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth_flow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 684\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_single_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    685\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_response_body\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpx\\_client.py\u001b[0m in \u001b[0;36msend_single_request\u001b[1;34m(self, request, timeout)\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m             )\n\u001b[0;32m    721\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, headers, stream, timeout)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                 response = connection.request(\n\u001b[1;32m--> 153\u001b[1;33m                     \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m                 )\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mNewConnectionRequired\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpcore\\_sync\\connection.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, headers, stream, timeout)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;34m\"connection.request method=%r url=%r headers=%r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         )\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_open_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTimeoutDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSyncSocketStream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpcore\\_sync\\http2.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, headers, stream, timeout)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstream_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh2_stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstream_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mh2_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_streams_semaphore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpcore\\_sync\\http2.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, headers, stream, timeout)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;31m# Receive the response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreceive_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m         \u001b[0mreason_phrase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_reason_phrase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         stream = SyncByteStream(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpcore\\_sync\\http2.py\u001b[0m in \u001b[0;36mreceive_response\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \"\"\"\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[0mevent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResponseReceived\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpcore\\_sync\\http2.py\u001b[0m in \u001b[0;36mwait_for_event\u001b[1;34m(self, stream_id, timeout)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstream_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreceive_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstream_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpcore\\_sync\\http2.py\u001b[0m in \u001b[0;36mreceive_events\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mRead\u001b[0m \u001b[0msome\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mH2\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \"\"\"\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[0mevents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh2_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreceive_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\httpcore\\_backends\\sync.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, n, timeout)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTimeoutDict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1054\u001b[0m                     \u001b[1;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m                     self.__class__)\n\u001b[1;32m-> 1056\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Machine Learning 1\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    929\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rev_translations = []\n",
    "for word in reviews_stopwords:\n",
    "    rev_translations.append(translator.translate(word).text)\n",
    "#reviews_eng = reviews_stopwords.apply(translator.translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDj0yFRu6qJ0"
   },
   "outputs": [],
   "source": [
    "rev_translations[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "4OrDA7V86qMj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41753 entries, 0 to 41752\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   stemming            41753 non-null  object  \n",
      " 1   review_score        41753 non-null  int64   \n",
      " 2   review_score_class  41753 non-null  category\n",
      " 3   review_sentiment    41753 non-null  category\n",
      "dtypes: category(2), int64(1), object(1)\n",
      "memory usage: 734.3+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olani\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\olani\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# let's break up the Discrepancy variable\n",
    "#But needs outliers to be removed\n",
    "import sys\n",
    "olist_rev_clean2['review_sentiment'] = pd.cut(olist_rev_clean2['review_score'],\n",
    "                                                 [0, 3, 5],\n",
    "                                                 2,\n",
    "                                                 labels=['negative','positive']) # this creates a new variable\n",
    "olist_rev_clean2['review_sentiment'] = olist_rev_clean2.copy()['review_sentiment'].astype(\"category\")\n",
    "olist_rev_clean2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "C3zH2GVj6qOe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemming</th>\n",
       "      <th>review_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>receb bem ant praz estipul</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parabém loj lannist ador compr internet segur prát parabém tod feliz pásco</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pouc trav val ta boa</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vend confi produt ok entreg ant praz</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            stemming  \\\n",
       "0                                                                         receb bem ant praz estipul   \n",
       "1                         parabém loj lannist ador compr internet segur prát parabém tod feliz pásco   \n",
       "2  aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh   \n",
       "3                                                                               pouc trav val ta boa   \n",
       "4                                                               vend confi produt ok entreg ant praz   \n",
       "\n",
       "  review_sentiment  \n",
       "0         positive  \n",
       "1         positive  \n",
       "2         positive  \n",
       "3         positive  \n",
       "4         positive  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_rev_clean4 = olist_rev_clean2.copy().drop(columns=['review_score', 'review_score_class']) \n",
    "olist_rev_clean4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "KcYyjzmP6qS3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41753 entries, 0 to 41752\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   stemming          41753 non-null  object  \n",
      " 1   review_sentiment  41753 non-null  category\n",
      "dtypes: category(1), object(1)\n",
      "memory usage: 367.2+ KB\n"
     ]
    }
   ],
   "source": [
    "olist_rev_clean4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "RD-NgjUN6qXc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35490.049999999996"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_rev_clean4.shape[0]*0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "kCsDiAwW6qZh"
   },
   "outputs": [],
   "source": [
    "#Stratified shuffle split for representative dataset.\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(olist_rev_clean4, olist_rev_clean4[\"review_sentiment\"]):\n",
    "    strat_train_set = olist_rev_clean4.loc[train_index]\n",
    "    strat_test_set = olist_rev_clean4.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "p9T-Cqij6qd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33402 entries, 25624 to 32688\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   stemming          33402 non-null  object  \n",
      " 1   review_sentiment  33402 non-null  category\n",
      "dtypes: category(1), object(1)\n",
      "memory usage: 554.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                               stemming review_sentiment\n",
       " 25624                                         bom recom         positive\n",
       " 5654     bom mor nort sempr dem cheg cois aqu bem rapid         positive\n",
       " 20891                                   bom compr stark         positive\n",
       " 28633  produt neg entreg loj neg deu satisf após contat         negative\n",
       " 5099                produt neg entreg dar satisf client         negative,\n",
       " None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set.head(), strat_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(strat_train_set[\"stemming\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(strat_train_set[\"review_sentiment\"])\n",
    "X_test = np.array(strat_test_set[\"stemming\"]) \n",
    "y_test = np.array(strat_test_set[\"review_sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation metric\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jul 31 20:05:23 2017\n",
    "\n",
    "@author: DIP\n",
    "@Copyright: Dipanjan Sarkar\n",
    "\"\"\"\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "\n",
    "\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    \n",
    "    print('Accuracy:', np.round(\n",
    "                        metrics.accuracy_score(true_labels, \n",
    "                                               predicted_labels),\n",
    "                        4))\n",
    "    print('Precision:', np.round(\n",
    "                        metrics.precision_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n",
    "    print('Recall:', np.round(\n",
    "                        metrics.recall_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n",
    "    print('F1 Score:', np.round(\n",
    "                        metrics.f1_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n",
    "                        \n",
    "\n",
    "def train_predict_model(classifier, \n",
    "                        train_features, train_labels, \n",
    "                        test_features, test_labels):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features) \n",
    "    return predictions    \n",
    "\n",
    "\n",
    "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
    "    \n",
    "    total_classes = len(classes)\n",
    "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n",
    "                                  labels=classes)\n",
    "    cm_frame = pd.DataFrame(data=cm, \n",
    "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
    "                                                  labels=level_labels), \n",
    "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
    "                                                labels=level_labels)) \n",
    "    print(cm_frame) \n",
    "\n",
    "\n",
    "def display_confusion_matrix_pretty(true_labels, predicted_labels, classes=[1,0]):\n",
    "    \n",
    "    total_classes = len(classes)\n",
    "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n",
    "                                  labels=classes)\n",
    "    cm_frame = pd.DataFrame(data=cm, \n",
    "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
    "                                                  labels=level_labels), \n",
    "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
    "                                                labels=level_labels)) \n",
    "    return cm_frame\n",
    "    \n",
    "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n",
    "\n",
    "    report = metrics.classification_report(y_true=true_labels, \n",
    "                                           y_pred=predicted_labels, \n",
    "                                           labels=classes) \n",
    "    print(report)\n",
    "    \n",
    "    \n",
    "    \n",
    "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n",
    "    print('Model Performance metrics:')\n",
    "    print('-'*30)\n",
    "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
    "    print('\\nModel Classification report:')\n",
    "    print('-'*30)\n",
    "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \n",
    "                                  classes=classes)\n",
    "    print('\\nPrediction Confusion Matrix:')\n",
    "    print('-'*30)\n",
    "    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n",
    "                             classes=classes)\n",
    "\n",
    "\n",
    "def plot_model_decision_surface(clf, train_features, train_labels,\n",
    "                                plot_step=0.02, cmap=plt.cm.RdYlBu,\n",
    "                                markers=None, alphas=None, colors=None):\n",
    "    \n",
    "    if train_features.shape[1] != 2:\n",
    "        raise ValueError(\"X_train should have exactly 2 columnns!\")\n",
    "    \n",
    "    x_min, x_max = train_features[:, 0].min() - plot_step, train_features[:, 0].max() + plot_step\n",
    "    y_min, y_max = train_features[:, 1].min() - plot_step, train_features[:, 1].max() + plot_step\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    clf_est = clone(clf)\n",
    "    clf_est.fit(train_features,train_labels)\n",
    "    if hasattr(clf_est, 'predict_proba'):\n",
    "        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
    "    else:\n",
    "        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])    \n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cmap)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(train_labels)\n",
    "    n_classes = len(le.classes_)\n",
    "    plot_colors = ''.join(colors) if colors else [None] * n_classes\n",
    "    label_names = le.classes_\n",
    "    markers = markers if markers else [None] * n_classes\n",
    "    alphas = alphas if alphas else [None] * n_classes\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y_enc == i)\n",
    "        plt.scatter(train_features[idx, 0], train_features[idx, 1], c=color,\n",
    "                    label=label_names[i], cmap=cmap, edgecolors='black', \n",
    "                    marker=markers[i], alpha=alphas[i])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_model_roc_curve(clf, features, true_labels, label_encoder=None, class_names=None):\n",
    "    \n",
    "    ## Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    if hasattr(clf, 'classes_'):\n",
    "        class_labels = clf.classes_\n",
    "    elif label_encoder:\n",
    "        class_labels = label_encoder.classes_\n",
    "    elif class_names:\n",
    "        class_labels = class_names\n",
    "    else:\n",
    "        raise ValueError('Unable to derive prediction classes, please specify class_names!')\n",
    "    n_classes = len(class_labels)\n",
    "    y_test = label_binarize(true_labels, classes=class_labels)\n",
    "    if n_classes == 2:\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            prob = clf.predict_proba(features)\n",
    "            y_score = prob[:, prob.shape[1]-1] \n",
    "        elif hasattr(clf, 'decision_function'):\n",
    "            prob = clf.decision_function(features)\n",
    "            y_score = prob[:, prob.shape[1]-1]\n",
    "        else:\n",
    "            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score)      \n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n",
    "                                 ''.format(roc_auc),\n",
    "                 linewidth=2.5)\n",
    "        \n",
    "    elif n_classes > 2:\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            y_score = clf.predict_proba(features)\n",
    "        elif hasattr(clf, 'decision_function'):\n",
    "            y_score = clf.decision_function(features)\n",
    "        else:\n",
    "            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        ## Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        ## Compute macro-average ROC curve and ROC area\n",
    "        # First aggregate all false positive rates\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        # Then interpolate all ROC curves at this points\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "        # Finally average it and compute AUC\n",
    "        mean_tpr /= n_classes\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        ## Plot ROC curves\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                 label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                       ''.format(roc_auc[\"micro\"]), linewidth=3)\n",
    "\n",
    "        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                 label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                       ''.format(roc_auc[\"macro\"]), linewidth=3)\n",
    "\n",
    "        for i, label in enumerate(class_labels):\n",
    "            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                           ''.format(label, roc_auc[i]), \n",
    "                     linewidth=2, linestyle=':')\n",
    "    else:\n",
    "        raise ValueError('Number of classes should be atleast 2 or more')\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\olani\\\\OneDrive\\\\Documents\\\\Data Science\\\\SMU-Data Science\\\\Natural Language Processing\\\\Text Analytics with Python_Dipanjan 2019\\\\Codes_Dipanjan 2019\\\\Ch05 - Text Classification'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change working directory to where I could locate the model_eval_util function\n",
    "os.chdir(r\"C:\\Users\\olani\\OneDrive\\Documents\\Data Science\\SMU-Data Science\\Natural Language Processing\\Text Analytics with Python_Dipanjan 2019\\Codes_Dipanjan 2019\\Ch05 - Text Classification\")\n",
    "#\"C:\\Users\\olani\\OneDrive\\Documents\\Data Science\\SMU-Data Science\\Machine Learning 1\\Olist_Dataset\"\n",
    "\n",
    "# get current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_evaluation_utils as meu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build BOW features on train reviews\n",
    "\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "cv_train_features = cv.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build TFIDF features on train reviews\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2), sublinear_tf=True)\n",
    "tv_train_features = tv.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test reviews into features\n",
    "cv_test_features = cv.transform(X_test)\n",
    "tv_test_features = tv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (33402, 84440)  Test features shape: (8351, 84440)\n"
     ]
    }
   ],
   "source": [
    "print('BOW model:> Train features shape:', cv_train_features.shape,' Test features shape:', cv_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF model:> Train features shape: (33402, 84440)  Test features shape: (8351, 84440)\n"
     ]
    }
   ],
   "source": [
    "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1)\n",
    "svm = SGDClassifier(loss='hinge', max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olani\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr_bow_predictions = meu.train_predict_model(classifier=lr,train_features=cv_train_features, \n",
    "                                         train_labels=y_train, test_features=cv_test_features, test_labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8991\n",
      "Precision: 0.8985\n",
      "Recall: 0.8991\n",
      "F1 Score: 0.8985\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.91      0.93      0.92      5336\n",
      "    negative       0.88      0.84      0.86      3015\n",
      "\n",
      "    accuracy                           0.90      8351\n",
      "   macro avg       0.89      0.89      0.89      8351\n",
      "weighted avg       0.90      0.90      0.90      8351\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-b2866ce1c41e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m meu.display_model_performance_metrics(true_labels=y_test,\n\u001b[0;32m      2\u001b[0m                                       \u001b[0mpredicted_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr_bow_predictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                                       classes=['positive', 'negative'])\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Documents\\Data Science\\SMU-Data Science\\Natural Language Processing\\Text Analytics with Python_Dipanjan 2019\\Codes_Dipanjan 2019\\Ch05 - Text Classification\\model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_model_performance_metrics\u001b[1;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n\u001b[1;32m--> 102\u001b[1;33m                              classes=classes)\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Data Science\\SMU-Data Science\\Natural Language Processing\\Text Analytics with Python_Dipanjan 2019\\Codes_Dipanjan 2019\\Ch05 - Text Classification\\model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_confusion_matrix\u001b[1;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[0;32m     60\u001b[0m     cm_frame = pd.DataFrame(data=cm, \n\u001b[0;32m     61\u001b[0m                             columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n\u001b[1;32m---> 62\u001b[1;33m                                                   labels=level_labels), \n\u001b[0m\u001b[0;32m     63\u001b[0m                             index=pd.MultiIndex(levels=[['Actual:'], classes], \n\u001b[0;32m     64\u001b[0m                                                 labels=level_labels)) \n",
      "\u001b[1;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=y_test,predicted_labels=lr_bow_predictions,\n",
    "                                      classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olani\\anaconda3\\envs\\Machine Learning 1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model on TF-IDF features\n",
    "lr_tfidf_predictions = meu.train_predict_model(classifier=lr,train_features=tv_train_features, \n",
    "                                         train_labels=y_train, test_features=tv_test_features, test_labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8997\n",
      "Precision: 0.8999\n",
      "Recall: 0.8997\n",
      "F1 Score: 0.8998\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.92      0.92      0.92      5336\n",
      "    negative       0.86      0.87      0.86      3015\n",
      "\n",
      "    accuracy                           0.90      8351\n",
      "   macro avg       0.89      0.89      0.89      8351\n",
      "weighted avg       0.90      0.90      0.90      8351\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-c7dbb0e73c1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m meu.display_model_performance_metrics(true_labels=y_test, predicted_labels=lr_tfidf_predictions,\n\u001b[1;32m----> 2\u001b[1;33m                                       classes=['positive', 'negative'])\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Documents\\Data Science\\SMU-Data Science\\Natural Language Processing\\Text Analytics with Python_Dipanjan 2019\\Codes_Dipanjan 2019\\Ch05 - Text Classification\\model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_model_performance_metrics\u001b[1;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n\u001b[1;32m--> 102\u001b[1;33m                              classes=classes)\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Data Science\\SMU-Data Science\\Natural Language Processing\\Text Analytics with Python_Dipanjan 2019\\Codes_Dipanjan 2019\\Ch05 - Text Classification\\model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_confusion_matrix\u001b[1;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[0;32m     60\u001b[0m     cm_frame = pd.DataFrame(data=cm, \n\u001b[0;32m     61\u001b[0m                             columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n\u001b[1;32m---> 62\u001b[1;33m                                                   labels=level_labels), \n\u001b[0m\u001b[0;32m     63\u001b[0m                             index=pd.MultiIndex(levels=[['Actual:'], classes], \n\u001b[0;32m     64\u001b[0m                                                 labels=level_labels)) \n",
      "\u001b[1;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=y_test, predicted_labels=lr_tfidf_predictions,\n",
    "                                      classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skater'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-3164ef2f1ab3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mskater\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_interpretation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlime_text\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLimeTextExplainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skater'"
     ]
    }
   ],
   "source": [
    "from skater.core.local_interpretation.lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Olist_reviews_NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
